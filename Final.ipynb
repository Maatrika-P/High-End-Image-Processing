{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikip\\anaconda3\\envs\\ennovate\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52\n",
      "Precision: 7\n",
      "Recall: 7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Step 1: Image Preprocessing\n",
    "def preprocess_image(image):\n",
    "    # Preprocessing code\n",
    "    new_width = image.shape[1]\n",
    "    new_height = image.shape[0]\n",
    "    resized_image = cv2.resize(image, (new_width, new_height))\n",
    "    blurred_image = cv2.GaussianBlur(resized_image, (5, 5), 0)\n",
    "    normalized_image = cv2.normalize(blurred_image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return normalized_image\n",
    "\n",
    "\n",
    "# Step 2: Feature Extraction\n",
    "def extract_features(image, max_feature_length):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a feature extraction algorithm (e.g., SIFT, SURF, etc.)\n",
    "    feature_extractor = cv2.SIFT_create()\n",
    "    keypoints, descriptors = feature_extractor.detectAndCompute(gray, None)\n",
    "\n",
    "    # Check if descriptors exist\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return None\n",
    "\n",
    "    # Reshape descriptors to be a 1-dimensional array\n",
    "    feature_vector = descriptors.flatten()\n",
    "\n",
    "    # Check if feature vector length exceeds the maximum feature length\n",
    "    if len(feature_vector) > max_feature_length:\n",
    "        feature_vector = feature_vector[:max_feature_length]\n",
    "    else:\n",
    "        # Pad the feature vector if it is shorter than the maximum feature length\n",
    "        feature_vector = np.pad(feature_vector, (0, max_feature_length - len(feature_vector)), mode='constant')\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "# Step 3: Image Registration with Robust Estimation\n",
    "def image_registration(image1, image2):\n",
    "    # Detect and match features\n",
    "    src_points, dst_points = detect_and_match_features(image1, image2)\n",
    "\n",
    "    # Perform robust estimation using RANSAC\n",
    "    transformation_matrix, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 5.0)\n",
    "\n",
    "    return transformation_matrix\n",
    "\n",
    "\n",
    "# Step 4: Perspective Transformation\n",
    "def perspective_transformation(image, transformation_matrix):\n",
    "    # Perspective transformation code\n",
    "    transformed_image = cv2.warpPerspective(image, transformation_matrix, (image.shape[1], image.shape[0]))\n",
    "    return transformed_image\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(image, max_feature_length):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a feature extraction algorithm (e.g., SIFT, SURF, etc.)\n",
    "    feature_extractor = cv2.SIFT_create()\n",
    "    keypoints, descriptors = feature_extractor.detectAndCompute(gray, None)\n",
    "\n",
    "    # Check if descriptors exist\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return None\n",
    "\n",
    "    # Reshape descriptors to be a 1-dimensional array\n",
    "    feature_vector = descriptors.flatten()\n",
    "\n",
    "    # Check if feature vector length exceeds the maximum feature length\n",
    "    if len(feature_vector) > max_feature_length:\n",
    "        feature_vector = feature_vector[:max_feature_length]\n",
    "    else:\n",
    "        # Pad the feature vector if it is shorter than the maximum feature length\n",
    "        feature_vector = np.pad(feature_vector, (0, max_feature_length - len(feature_vector)), mode='constant')\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "def determine_max_feature_length(train_folder):\n",
    "    max_feature_length = 0\n",
    "\n",
    "    for filename in os.listdir(train_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            train_image_path = os.path.join(train_folder, filename)\n",
    "            train_image = cv2.imread(train_image_path)\n",
    "            processed_train_image = preprocess_image(train_image, new_width, new_height)\n",
    "\n",
    "            feature_vector = extract_features(processed_train_image, 128)\n",
    "            if feature_vector is not None and len(feature_vector) > max_feature_length:\n",
    "                max_feature_length = len(feature_vector)\n",
    "\n",
    "    return max_feature_length\n",
    "\n",
    "\n",
    "def find_roi(image):\n",
    "    # Convert the image to grayscale.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply adaptive threshold to obtain a binary image.\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "    # Find contours in the binary image.\n",
    "    cnts, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest contour that is similar to the brand name.\n",
    "    largest_cnt = None\n",
    "    max_area = 0\n",
    "    for cnt in cnts:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > max_area and area > 1000:\n",
    "            largest_cnt = cnt\n",
    "            max_area = area\n",
    "\n",
    "    # Get the bounding box of the largest contour.\n",
    "    if largest_cnt is not None:\n",
    "        x, y, w, h = cv2.boundingRect(largest_cnt)\n",
    "\n",
    "        # Return the bounding box.\n",
    "        return x, y, w, h\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Step 5: Complete Image Registration Pipeline\n",
    "def register_images(train_folder, validation_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    train_images = []\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "\n",
    "    for folder_name in ['authentic', 'counterfeit']:\n",
    "        folder_path = os.path.join(train_folder, folder_name)\n",
    "\n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "\n",
    "        label = 1 if folder_name == 'authentic' else 0  # Assign label 1 for 'authentic' folder and 0 for 'counterfeit' folder\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                train_image = cv2.imread(image_path)\n",
    "\n",
    "                # Find the ROI for the current train image\n",
    "                x, y, w, h = find_roi(train_image)\n",
    "\n",
    "                if x is not None:\n",
    "                    # Crop the ROI from the image\n",
    "                    roi = train_image[y:y + h, x:x + w]\n",
    "\n",
    "                    # Preprocess the ROI\n",
    "                    processed_roi = preprocess_image(roi)\n",
    "\n",
    "                    train_images.append(processed_roi)\n",
    "\n",
    "                    feature_vector = extract_features(processed_roi, 10)  # Replace max_feature_length with your desired value\n",
    "                    if feature_vector is not None:\n",
    "                        train_features.append(feature_vector)\n",
    "                        train_labels.append(label)\n",
    "                    else:\n",
    "                        print(\"No features found for image:\", filename)\n",
    "                else:\n",
    "                    print(\"ROI not found for image:\", filename)\n",
    "\n",
    "    # Check if any train features were extracted\n",
    "    if len(train_features) == 0:\n",
    "        print(\"No train features found.\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    train_features = np.array(train_features)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Apply clustering to train features and obtain cluster centers\n",
    "    num_clusters = 10\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(train_features)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "    # Train the classifier with the extracted features\n",
    "    base_classifier = RandomForestClassifier()\n",
    "    bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10)  # Change the number of estimators as needed\n",
    "    bagging_classifier.fit(train_features, train_labels)\n",
    "\n",
    "    # Move processed validation images to final validation folder\n",
    "    final_validation_folder = os.path.join(output_folder, \"validation\")\n",
    "    if not os.path.exists(final_validation_folder):\n",
    "        os.makedirs(final_validation_folder)\n",
    "\n",
    "    validation_images = []\n",
    "    validation_features = []\n",
    "\n",
    "    for filename in os.listdir(validation_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            validation_image_path = os.path.join(validation_folder, filename)\n",
    "            validation_image = cv2.imread(validation_image_path)\n",
    "\n",
    "            # Find the ROI for the current validation image\n",
    "            x, y, w, h = find_roi(validation_image)\n",
    "\n",
    "            if x is not None:\n",
    "                # Crop the ROI from the image\n",
    "                roi = validation_image[y:y + h, x:x + w]\n",
    "\n",
    "                # Preprocess the ROI\n",
    "                processed_roi = preprocess_image(roi)\n",
    "\n",
    "                validation_images.append(processed_roi)\n",
    "\n",
    "                feature_vector = extract_features(processed_roi, 10)  # Replace max_feature_length with your desired value\n",
    "                if feature_vector is not None:\n",
    "                    validation_features.append(feature_vector)\n",
    "                else:\n",
    "                    print(\"No features found for image:\", filename)\n",
    "            else:\n",
    "                print(\"ROI not found for image:\", filename)\n",
    "\n",
    "    # Check if any validation features were extracted\n",
    "    if len(validation_features) == 0:\n",
    "        print(\"No validation features found.\")\n",
    "        return 0, 0, 0\n",
    "\n",
    "    validation_features = np.array(validation_features)\n",
    "\n",
    "    # Transform validation features to match the cluster centers\n",
    "    transformed_validation_features = kmeans.transform(validation_features)\n",
    "\n",
    "    # Make predictions on the transformed validation features\n",
    "    validation_predictions = bagging_classifier.predict(transformed_validation_features)\n",
    "\n",
    "    # Move the validation images to the corresponding output folders based on the predictions\n",
    "    for i, prediction in enumerate(validation_predictions):\n",
    "        filename = os.listdir(validation_folder)[i]\n",
    "        source_path = os.path.join(validation_folder, filename)\n",
    "        destination_folder = os.path.join(final_validation_folder, \"authentic\" if prediction == 1 else \"counterfeit\")\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "        if not os.path.exists(destination_folder):\n",
    "            os.makedirs(destination_folder)\n",
    "\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "    return len(train_images), len(validation_images), len(validation_predictions)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "  \n",
    "    train_folder = r\"C:\\Users\\mikip\\OneDrive\\Desktop\\Ennovate\\DataSet\\Train_Images\"\n",
    "    validation_folder = r\"C:\\Users\\mikip\\OneDrive\\Desktop\\Ennovate\\DataSet\\Valid_Images\"\n",
    "    output_folder = r\"C:\\Users\\mikip\\OneDrive\\Desktop\\Ennovate\\output\"\n",
    "\n",
    "    accuracy, precision, recall = register_images(train_folder, validation_folder, output_folder)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ennovate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
